{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4753077,"sourceType":"datasetVersion","datasetId":2750746}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dakotachang/gmm-dsaproject?scriptVersionId=285816228\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Bird Sound Gaussian Mixture Model Project\nDSA Final Project - Dakota &amp; Rishika\n\n### Introduction\n\nA Gaussian Mixture Model (GMM) is a probabilistic model that assumes data points are generated from a mixture of several Gaussian (normal) distributions with unknown parameters. A Gaussian Mixture Model assumes that the data is generated from a mixture of K Gaussian distributions, each representing a cluster. Every Gaussian has its own mean μk​, covariance Σk​ and mixing weight πk​.\n\nBelow is the total likelihood of observing xn under all Gaussians:\n\n![GMM Probability Equation](/gmm_equation.png)\n\n****where:****\n\n- zn​ is a latent variable indicating which Gaussian the point belongs to.\n- πk​ is the mixing probability of the k-th Gaussian.\n- N(xn ∣ μk, Σk) is the Gaussian distribution with mean μk​ and covariance Σk.\n\nThis represents how well the mixture as a whole explains the data point.\n\nGMMs are trained using the Expectation-Maximization Algorithm, an iterative algorithm used to assign unknown parameters in probabilistic models. The algorithm works in two steps:\n\n****E-step (Expectation)****: Compute the responsibility of each cluster for every data point using current parameter values.\n\n****M-step (Maximization):**** Update\n- Means μk\n- Covariances Σk\n- Mixing coefficients πk\n\nThe process continues until the model's log-likelihood stabilizes.\n\nIn GMM, each cluster is a Gaussian defined by:\n\n- ****Mean (μ):**** Center of the cluster.\n- ****Covariance (Σ):**** Controls the shape, orientation and spread of the cluster.\n\nThe covariance matrix of a Gaussian distribution determines the directions and lengths of the axes of its density contours, all of which are ellipsoids.\n\nThese four types of mixture models can be illustrated in full generality using the two-dimensional case. In each of these contour plots of the mixture density, two components are located at (0,0) and (4,5) with weights 3/5 and 2/5 respectively. The different weights will cause the _sets_ of contours to look slightly different even when the covariance matrices are the same, but the overall shapes of individual contours will still be similar for identical matrices.\n\n![Covariance Models for GMM](/gmm_covariance.png)\n\n- **Full** means the components may independently adopt any position and shape.\n- **Tied** means they have the same shape, but that shape may be anything.\n- **Diagonal** means the contour axes are oriented along the coordinate axes, but otherwise the eccentricities may vary between components.\n- **Spherical** is a \"diagonal\" situation with circular contours (spherical in higher dimensions, whence the name).\n\n### Gaussian Mixture Model vs. K-means Clustering\n\nWhile K-means clustering forms groups by minimizing the distance between data points and a central point, mixture models such as Gaussian Mixture Models (GMMs) define clusters using probability distributions that can take on elliptical shapes based on their parameters. Because of this flexibility, GMMs are better suited for datasets that are not easily separable and require more complex cluster boundaries. They also support soft clustering, assigning each point a probability of belonging to multiple clusters rather than a single hard assignment.\n\nIn contrast, K-means is a much simpler and more computationally efficient method. It performs well on low-dimensional data with clearly defined, spherical clusters. However, K-means is highly sensitive to outliers and performs poorly when clusters are non-spherical or vary in size and density.\n\n![KNN vs GMM](/knn_vs_gmm.png)\n\nSince we are working with MFCC spectrograms for bird sounds, the feature space contains over 30 coefficients, making the data high-dimensional. In this setting, K-means becomes less effective due to its reliance on simple, spherical cluster boundaries. Additionally, because we want a model that can accommodate varying cluster shapes for more accurate predictions, a Gaussian Mixture Model is better suited for this task.\n\n### Our Project\nOur project focuses on identifying and clustering bird chirps using GMMs. By extracting Mel-Frequency Cepstral Coefficients (MFCCs) from audio recordings sourced from the Kaggle Bird Sounds dataset, we aim to uncover patterns in bird calls without relying on labeled data. This work allows us to explore the challenges of applying unsupervised learning to real-world, noisy environmental audio.\n\nNow that we understand how a GMM works, we will download the necessary libraries and input our bird sound data.","metadata":{}},{"cell_type":"markdown","source":"## Import necessary libraries","metadata":{}},{"cell_type":"code","source":"!pip install python_speech_features","metadata":{"_uuid":"28aa4b10-2608-4d45-a611-c986257eaa70","_cell_guid":"859ae3c6-abc9-4762-b223-6641156aa4c8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-12T21:21:44.652104Z","iopub.execute_input":"2025-12-12T21:21:44.652403Z","iopub.status.idle":"2025-12-12T21:21:48.829675Z","shell.execute_reply.started":"2025-12-12T21:21:44.652376Z","shell.execute_reply":"2025-12-12T21:21:48.828599Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# system\nimport os\nimport random\nfrom pathlib import Path\nfrom collections import defaultdict\n\n# graphing and calculations\nimport numpy as np\nimport librosa\nimport librosa.display\nfrom python_speech_features import mfcc, delta\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport pickle","metadata":{"_uuid":"2bc6877b-b4a9-4c16-8a81-f518ee223bf1","_cell_guid":"b4800589-14a5-4687-8549-1f556ffb7d5d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.451181Z","iopub.execute_input":"2025-12-12T21:20:05.45149Z","iopub.status.idle":"2025-12-12T21:20:05.561454Z","shell.execute_reply.started":"2025-12-12T21:20:05.45145Z","shell.execute_reply":"2025-12-12T21:20:05.559809Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import audio and extract mfcc features","metadata":{}},{"cell_type":"code","source":"def extract_features(audio_path, n_mfcc=40):\n    y, sr = librosa.load(audio_path, sr=None, mono=True)\n\n    # pre-emphasis\n    y = np.append(y[0], y[1:] - 0.97 * y[:-1])\n\n    mfcc_feat = mfcc(\n        y, sr,\n        winlen=0.05, winstep=0.01,\n        numcep=n_mfcc, nfilt=64, nfft=4096,\n        appendEnergy=True\n    )\n\n    if mfcc_feat.shape[0] < 3:\n        return None\n\n    mfcc_feat = StandardScaler().fit_transform(mfcc_feat)\n    d1 = delta(mfcc_feat, 2)\n    d2 = delta(d1, 2)\n\n    return np.hstack([mfcc_feat, d1, d2])","metadata":{"_uuid":"bd05ff82-fc45-4068-a3f3-707253212610","_cell_guid":"270b80a4-8762-4d70-a27d-e29b2ab74ec6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.562314Z","iopub.status.idle":"2025-12-12T21:20:05.562666Z","shell.execute_reply.started":"2025-12-12T21:20:05.562492Z","shell.execute_reply":"2025-12-12T21:20:05.562508Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rootdirs = [\n    '/kaggle/input/sound-of-114-species-of-birds-till-2022/Voice of Birds/Voice of Birds/Andean Guan_sound',\n    '/kaggle/input/sound-of-114-species-of-birds-till-2022/Voice of Birds/Voice of Birds/Andean Tinamou_sound',\n    '/kaggle/input/sound-of-114-species-of-birds-till-2022/Voice of Birds/Voice of Birds/Black-billed Brushturkey_sound',\n    '/kaggle/input/sound-of-114-species-of-birds-till-2022/Voice of Birds/Voice of Birds/Chaco Chachalaca_sound',\n    '/kaggle/input/sound-of-114-species-of-birds-till-2022/Voice of Birds/Voice of Birds/Emu_sound',\n    '/kaggle/input/sound-of-114-species-of-birds-till-2022/Voice of Birds/Voice of Birds/North Island Brown Kiwi_sound'\n]\n\nall_files = []\nfor folder in rootdirs:\n    bird = Path(folder).name.replace(\"_sound\", \"\")\n    for f in Path(folder).glob(\"*.mp3\"):\n        all_files.append((bird, f))\n\nspecies_dict = defaultdict(list)\nfor bird, f in all_files:\n    species_dict[bird].append(f)\n\n# train test split, 70/30 due to size of ~30 audios per bird\ntrain_pairs, test_pairs = [], []\nfor bird, files in species_dict.items():\n    tr, ts = train_test_split(files, test_size=0.3, random_state=42)\n    train_pairs += [(bird, f) for f in tr]\n    test_pairs  += [(bird, f) for f in ts]\n\nprint(f\"Train: {len(train_pairs)} | Test: {len(test_pairs)}\")","metadata":{"_uuid":"517ad36b-e362-444c-a487-51580bf0427e","_cell_guid":"81bdd9d4-229b-4e83-b719-06a16d12a366","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.563744Z","iopub.status.idle":"2025-12-12T21:20:05.563972Z","shell.execute_reply.started":"2025-12-12T21:20:05.563861Z","shell.execute_reply":"2025-12-12T21:20:05.563871Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training the GMM for each bird\n\nThis section trains a GMM for each bird species' chirp.","metadata":{}},{"cell_type":"code","source":"def train_gmm(features, name, components=16):\n    X = np.vstack(features)\n    gmm = GaussianMixture(\n        n_components=components,\n        covariance_type=\"diag\",\n        n_init=4,\n        max_iter=300\n    ).fit(X)\n\n    with open(f\"{name}.gmm\", \"wb\") as f:\n        pickle.dump(gmm, f)\n\n    return gmm\n    \nspecies_features = defaultdict(list)\n\nfor bird, file_path in train_pairs:\n    feats = extract_features(str(file_path))\n    if feats is not None:\n        species_features[bird].append(feats)\n\nmodels = {}\nfor bird, feats in species_features.items():\n    print(f\"Training {bird} ({len(feats)} files)\")\n    models[bird] = train_gmm(feats, bird)","metadata":{"_uuid":"69180fe6-0cfa-4c8d-92ed-4f42c72a8838","_cell_guid":"984db2f3-5229-4871-aa08-943adb81b15e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.564809Z","iopub.status.idle":"2025-12-12T21:20:05.565153Z","shell.execute_reply.started":"2025-12-12T21:20:05.564952Z","shell.execute_reply":"2025-12-12T21:20:05.564964Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction and Evaluation","metadata":{}},{"cell_type":"code","source":"def predict_species(audio_path, models):\n    feats = extract_features(str(audio_path))\n    scores = {b: m.score(feats) for b, m in models.items()}\n    return max(scores, key=scores.get)\n\ny_true, y_pred = [], []\n\nfor bird, file_path in test_pairs:\n    try:\n        pred = predict_species(file_path, models)\n        y_true.append(bird)\n        y_pred.append(pred)\n    except:\n        pass\n\nprint(\"Accuracy:\", accuracy_score(y_true, y_pred))\nprint(classification_report(y_true, y_pred))","metadata":{"_uuid":"be9e0716-1941-409e-a6fc-27b1a2f68c24","_cell_guid":"19c5f258-32c7-4972-b383-e8b1d7c5f02b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.566392Z","iopub.status.idle":"2025-12-12T21:20:05.566648Z","shell.execute_reply.started":"2025-12-12T21:20:05.566538Z","shell.execute_reply":"2025-12-12T21:20:05.56655Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Accuracy of 82% shows that the algorithm can effective differentiate bird species based on the audio of them chirping. In particular, the model has a strong performance on acoustically distinct species like Black-billed Brushturkey (F1 = 0.92) and Andean Guan (F1 = 0.82). Errors are primarily due to lower recall on Emu and Kiwi, suggesting overlap in their acoustic feature distributions rather than systematic model failure.","metadata":{}},{"cell_type":"markdown","source":"## Plots","metadata":{}},{"cell_type":"code","source":"MAX_FRAMES_PER_FILE = 150\n\nX_frames, labels, frame_files = [], [], []\n\nfor bird, file_path in test_pairs:\n    feats = extract_features(str(file_path))\n    if feats is None:\n        continue\n\n    idx = np.random.choice(len(feats), min(MAX_FRAMES_PER_FILE, len(feats)), replace=False)\n    for i in idx:\n        X_frames.append(feats[i])\n        labels.append(bird)\n        frame_files.append(file_path.name)\n\nX_frames = np.nan_to_num(np.asarray(X_frames, dtype=np.float32))\n\npca = PCA(n_components=20, random_state=42)\nX_pca = pca.fit_transform(X_frames)\n\ntsne = TSNE(\n    n_components=2,\n    perplexity=40,\n    init=\"pca\",\n    learning_rate=\"auto\",\n    random_state=42\n)\nX_tsne = tsne.fit_transform(X_pca)\n\ndf = pd.DataFrame({\n    \"x\": X_tsne[:, 0],\n    \"y\": X_tsne[:, 1],\n    \"species\": labels,\n    \"file\": frame_files\n})","metadata":{"_uuid":"da059684-4915-4621-8ffc-71bbd1f57d7a","_cell_guid":"c6097918-459b-494c-bc32-1f42fa288cd8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.567553Z","iopub.status.idle":"2025-12-12T21:20:05.567775Z","shell.execute_reply.started":"2025-12-12T21:20:05.567662Z","shell.execute_reply":"2025-12-12T21:20:05.567672Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.scatter(\n    df,\n    x=\"x\",\n    y=\"y\",\n    color=\"species\",\n    opacity=0.6,\n    title=\"Frame-level MFCC Embedding (PCA -> t-SNE) - All Species\",\n    width=900,\n    height=650\n)\n\nfig.update_traces(marker=dict(size=4))\nfig.update_layout(\n    xaxis_title=\"t-SNE x\",\n    yaxis_title=\"t-SNE y\"\n)\n\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.568696Z","iopub.status.idle":"2025-12-12T21:20:05.569052Z","shell.execute_reply.started":"2025-12-12T21:20:05.568858Z","shell.execute_reply":"2025-12-12T21:20:05.568873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_species_grid(df, species_name):\n    files = df[df[\"species\"] == species_name][\"file\"].unique()\n    examples = random.sample(list(files), min(3, len(files)))\n\n    fig = make_subplots(\n        rows=2, cols=2,\n        subplot_titles=[\n            f\"Example 1: {examples[0]}\",\n            f\"Example 2: {examples[1]}\",\n            f\"Example 3: {examples[2]}\",\n            \"All Frames (Highlighted)\"\n        ]\n    )\n\n    for i, fname in enumerate(examples):\n        sub = df[df[\"file\"] == fname]\n        fig.add_trace(\n            go.Scatter(x=sub.x, y=sub.y, mode=\"markers\",\n                       marker=dict(size=5, opacity=0.7)),\n            row=1 if i < 2 else 2,\n            col=1 if i % 2 == 0 else 2\n        )\n\n    fig.add_trace(\n        go.Scatter(x=df.x, y=df.y, mode=\"markers\",\n                   marker=dict(size=4, color=\"lightgray\", opacity=0.25)),\n        row=2, col=2\n    )\n\n    sub = df[df[\"species\"] == species_name]\n    fig.add_trace(\n        go.Scatter(x=sub.x, y=sub.y, mode=\"markers\",\n                   marker=dict(size=5, color=\"red\", opacity=0.85)),\n        row=2, col=2\n    )\n\n    fig.update_layout(\n        title=f\"Frame-level MFCC Clusters — {species_name}\",\n        width=900,\n        height=800,\n        showlegend=False\n    )\n    fig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.570153Z","iopub.status.idle":"2025-12-12T21:20:05.570415Z","shell.execute_reply.started":"2025-12-12T21:20:05.570298Z","shell.execute_reply":"2025-12-12T21:20:05.570309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for species in sorted(df[\"species\"].unique()):\n    plot_species_grid(df, species)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T21:20:05.571272Z","iopub.status.idle":"2025-12-12T21:20:05.571585Z","shell.execute_reply.started":"2025-12-12T21:20:05.571406Z","shell.execute_reply":"2025-12-12T21:20:05.571423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Where GMM is Useful\n\nGaussian Mixture Models (GMMs) are used widely across industries as they can uncover underlying patterns in data through clustering, detecting anomalies, segmenting images into meaningful patterns for applications such as medical imaging, and perform density estimation to model complex probability distributions for generative tasks.\n\nGMMs offer several advantages. They can represent flexible, non-spherical, and overlapping cluster shapes, and they produce soft, probabilistic cluster memberships rather than hard labels. They also handle missing data effectively and rely on interpretable parameters—each Gaussian component has a clear mean, covariance, and weight that together describe its contribution to the mixture.\n\n#### Use-Cases\n\n- Marketing, medicine, genetics (clustering)\n- Fraud detection, medical error detection (anomaly detection)\n- Medical and remote sensing imagery (image segmentation)\n- Generative modeling (density estimation)","metadata":{}}]}